# -*- coding: utf-8 -*-
"""SHL_bot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T5Qt-dZYylle34jKyDbk09o1apHEruEW
"""


def main(question):
            from langchain.chains import RetrievalQAWithSourcesChain
            from langchain.chat_models import ChatOpenAI
            from langchain_core.documents import Document
            from dotenv import load_dotenv, find_dotenv
            from dotenv import load_dotenv
            from langchain_openai import OpenAI
            from langchain.vectorstores import FAISS
            from langchain_openai import OpenAIEmbeddings
            from langchain.prompts import PromptTemplate
            from langchain.chains import RetrievalQA
            import os

            api_key = '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'

            dir_path = os.path.dirname(os.path.realpath(__file__))
            data_file_path = os.path.join(dir_path, 'individual_SHL_assessment_with_description.pkl')
            data2_file_path = os.path.join(dir_path, 'prepacked_SHL_assessment_with_description.pkl')


            import pickle
            with open(data_file_path, 'rb') as file:
                data = pickle.load(file)

            import pickle
            with open(data2_file_path, 'rb') as file:
                data2 = pickle.load(file)

            def clean_data(data):
                  for i in range(len(data)):
                        structured_data = dict()
                        index_test_type = data[i]['info'].split("\n").index("Test Type:")
                        new_data = data[i]['info'].split("\n")[:index_test_type]
                        structured_data["Description"] = new_data[1]
                        new_data = new_data[2:]
                        try:
                            index_job_level = new_data.index('Job levels')
                            structured_data["Job levels"] = new_data[index_job_level + 1]
                            new_data.pop(index_job_level)
                            new_data.pop(index_job_level)
                        except:
                          structured_data["Job level"] = ''
                        try:
                            index_language_level = new_data.index('Languages')
                            structured_data["Languages"] = new_data[index_language_level + 1]
                            new_data.pop(index_language_level)
                            new_data.pop(index_language_level)
                        except:
                            structured_data["Languages"] = ''

                        try:
                            index_assessment_level = new_data.index('Assessment length')
                            structured_data["Assessmenet Length"] = new_data[index_assessment_level + 1]
                            new_data.pop(index_assessment_level)
                            new_data.pop(index_assessment_level)
                        except:
                            structured_data["Assessmenet Length"] = ''
                        if new_data != []:
                            structured_data['extra info']=''.join(new_data)

                        data[i].pop('info')
                        data[i].update(structured_data)
                  return data

            data2 = clean_data(data2)

            data = clean_data(data)

            final_data = data + data2

            docs = [Document(page_content=i['Description'], metadata={'href':i['href']}) for i in final_data if type(i)=='dict']



            # user_query = "Assessment for Java development and business collaboration, suitable for mid-level professionals, duration approximately 40 minutes."
            # user_query = "I am looking for a COO for my\
            # company in China and I want to see\
            # if they are culturally a right fit for\
            # our company. Suggest me an\
            # assessment that they can complete\
            # in about an hour"
            # user_query = """Find me 1 hour long assesment for
            # the below job at SHL
            # Job Description
            # Join a community that is shaping
            # the future of work! SHL, People
            # Science. People Answers.
            # Are you a seasoned QA Engineer
            # with a flair for innovation? Are you
            # ready to shape the future of talent
            # assessment and empower
            # organizations to unlock their full
            # potential? If so, we want you to be a
            # part of the SHL Team! As a QA
            # Engineer, you will be involved in
            # creating and implementing software
            # solutions that contribute to the
            # development of our groundbreaking
            # products.
            # An excellent benefit package is
            # offered in a culture where career
            # development, with ongoing
            # manager guidance, collaboration,
            # flexibility, diversity, and inclusivity
            # are all intrinsic to our culture. There
            # is a huge investment in SHL
            # currently so there’s no better time
            # to become a part of something
            # transformational.
            # What You Will Be Doing
            # Getting involved in engineering
            # quality assurance and providing
            # inputs when required.
            # Create and develop test plans for
            # various forms of testing.
            # Conducts and/or participates in
            # formal and informal test case
            # reviews.
            # Develop and initiate functional
            # tests and regression tests.
            # Rolling out improvements for
            # testing and quality processes.
            # Essential
            # What we are looking for from you
            # What SHL Can Offer You
            # Diversity, equity, inclusion and
            # accessibility are key threads in the
            # fabric of SHL’s business and culture
            # (find out more about DEI and
            # accessibility at SHL )
            # Employee benefits package that
            # takes care of you and your family.
            # Support, coaching, and on-the-job
            # development to achieve career
            # success
            # A fun and flexible workplace where
            # you’ll be inspired to do your best
            # work (find out more LifeAtSHL )
            # The ability to transform workplaces
            # around the world for others.
            # SHL is an equal opportunity
            # employer. We support and
            # encourage applications from a
            # diverse range of candidates. We
            # can, and do make adjustments to
            # make sure our recruitment process
            # is as inclusive as possible.
            # SHL is an equal opportunity
            # employer."""
            #
            # user_query = "Assessment for Java development and business collaboration, suitable for mid-level professionals, duration approximately 40 minutes."

            prompt = f"""
            
                    You are a smart assistant that reformulates user queries about 'recruitment test assessments' for hiring as stored in our company database.
                    Your job is to **extract relevant information** from the user prompt. In particular try to answer these questions:
                    
                    1. What kind of test is the user looking for from this list:
                    
                       'A': 'Ability and Aptitude'
                       'B': 'Biodata and Situational judgement'
                       'C': 'Competencies', 'D': 'Developement & 360'
                       'E': 'Assessment Exercises'
                       'K': 'Knowledge and skills'
                       'P': 'Personality and Behaviour'
                       'S': 'Simulations'
                    
                    
                    2. What kind of job level should the test be based on:
                    
                       'Director',
                       'Entry-Level',
                       'Executive',
                       'Front Line Manager',
                       'General Population',
                       'Graduate',
                       'Manager',
                       'Mid-Professional',
                       'Professional Individual Contributor',
                       'Supervisor',
                       'Director',
                       'Entry-Level',
                       'Executive',
                       'Front Line Manager',
                       'General Population',
                       'Graduate',
                       'Manager',
                       'Mid-Professional',
                       'Professional Individual Contributor',
                       'Supervisor'
                    
                    3. Is there a specific language that the user wants:
                    
                         'Arabic',
                         'Chinese Simplified',
                         'Chinese Traditional',
                         'Czech',
                         'Danish',
                         'Dutch',
                         'English (Australia)',
                         'English (Canada)',
                         'English (South Africa)',
                         'English (USA)',
                         'English International',
                         'Estonian',
                         'Finnish',
                         'Flemish',
                         'French',
                         'French (Belgium)',
                         'French (Canada)',
                         'German',
                         'Greek',
                         'Hungarian',
                         'Icelandic',
                         'Indonesian',
                         'Italian',
                         'Japanese',
                         'Korean',
                         'Latin American Spanish',
                         'Latvian',
                         'Lithuanian',
                         'Malay',
                         'Norwegian',
                         'Polish',
                         'Portuguese',
                         'Portuguese (Brazil)',
                         'Romanian',
                         'Russian',
                         'Serbian',
                         'Slovak',
                         'Spanish',
                         'Swedish',
                         'Thai',
                         'Turkish',
                         'Vietnamese'
                    
                    4.What is the length of the test the user is looking for?
                    
                    Original query:
                    '{question}'
                                       
                    Based on the above answers you obtain from the user prompt, structure your output STRICTLY IN **JSON** form:
                    
                    
                    Test Type : <Test type>
                    Job level : <Job level>
                    Language : <Language>
                    Assessment time : <Assessment time>
                    Description: <First determine whether the '{question}' is a job posting or an individual recruiter. Then based on this information
                                       Explain in briefly and clearly without missing any relevant details **ONLY** the job requirements or what the recruiter wants.> """



            # old
            # import openai

            # completion = openai.ChatCompletion.acreate(model="gpt-3.5-turbo", messages=[{"role": "user", "content": "Hello world"}])

            # # new
            # from openai import AsyncOpenAI

            # client = AsyncOpenAI()
            # completion = await client.chat.completions.create(model="gpt-3.5-turbo", messages=[{"role": "user", "content": "Hello world"}])

            # completion = openai.chat.completions.create(
            #     model="gpt-4",
            #     messages=[
            #         {
            #             "role": "user",
            #             "content": prompt,
            #         },
            #     ],
            # )
            # response = completion.choices[0].message.content
            # print(response)

            # import json
            # json_dict = json.loads(response)

            # print(json_dict)

            # import tiktoken
            # encoder = tiktoken.get_encoding("cl100k_base")

            # #text-embedding-ada-002 is the 2nd gen embedding models   embedding dimension= 1536

            # tokens_per_docs = [len(encoder.encode(doc.page_content)) for doc in docs]

            # total_tokens = sum(tokens_per_docs)
            # cost_per_1000_tokens = 0.0001
            # cost = (total_tokens / 1000) * cost_per_1000_tokens



            embeddings = OpenAIEmbeddings(model="text-embedding-3-small", api_key=api_key)
            vector_store = FAISS.from_documents(docs, embeddings)

            # llm = OpenAI(api_key=api_key)
            retriever = vector_store.as_retriever(search_kwargs={"k": 10})

            

            DOCUMENT_PROMPT = """
            {page_content}
            source : {href}
            """

            QUESTION_PROMPT = """
            Given the user query {question} and the relevant documents {summaries} provide the final answer to user.
            **DO NOT MAKE UP STUFF**. Just stick to the information provided in {summaries} and answer the user query
            **STRICLTLY USE ALL THE {summaries} in your answer:
            
            FINAL ANSWER:
            """

            document_prompt = PromptTemplate.from_template(DOCUMENT_PROMPT)
            question_prompt = PromptTemplate.from_template(QUESTION_PROMPT)



            qa_with_sources = RetrievalQAWithSourcesChain.from_chain_type(
                            chain_type = "stuff",
                            llm = ChatOpenAI(model_name = "gpt-3.5-turbo", temperature =0),
                            chain_type_kwargs = {
                                "prompt": question_prompt,
                                "document_prompt": document_prompt,
                            },
                            retriever = retriever,

                            )

            return  qa_with_sources(question)




if __name__ == '__main__':
    main()


            



